{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#following along the youtube tutorial: https://www.youtube.com/watch?v=BiS-uKoK5GY\n",
    "\n",
    "#Start of Step 1 of tutorial, Setup: \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#set path to the file of the github repo --> finder, right click on openbiomechanics, option, copy path\n",
    "path_github_repo = \"/Users/leofeingold/Documents/GitHub/openbiomechanics\"\n",
    "\n",
    "#change the directory to the repo path\n",
    "os.chdir(path_github_repo)\n",
    "\n",
    "#list the diectory\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set path to baseball pitching folder\n",
    "os.listdir('baseball_pitching')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set path to baseball pitching data\n",
    "pitching_data_path = os.path.join('baseball_pitching', 'data')\n",
    "\n",
    "os.listdir(pitching_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the metadata.csv\n",
    "with open(os.path.join(pitching_data_path, 'metadata.csv'), 'r') as f:\n",
    "    metadata = pd.read_csv(f)\n",
    "\n",
    "#end of Step 1 of tutorial, Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start of Step 2 of tutorial, Explore Metadata CSV\n",
    "\n",
    "#list metadata headers\n",
    "metadata.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print metadata columns\n",
    "print(metadata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print metadata shape\n",
    "\n",
    "metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the number of users, sessions and trials\n",
    "num_users = len(metadata['user'].unique())\n",
    "num_sessions = len(metadata['session'].unique())\n",
    "num_trials = len(metadata['session_pitch'].unique())\n",
    "print(f\"We have {num_trials} trials from {num_sessions} sessions and {num_users} users.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise: find the average age, height and weight of a pitcher in the data\n",
    "\n",
    "ave_age = metadata['age_yrs'].mean()\n",
    "ave_height = metadata['session_height_m'].mean()\n",
    "ave_weight = metadata['session_mass_kg'].mean()\n",
    "\n",
    "print(f\"Average Age: {ave_age}, Average Height (meters): {ave_height}, Average Weight (kilograms): {ave_weight}\")\n",
    "\n",
    "#End of Step 2 of tutorial, Explore Metadata CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start of Step 3 of tutorial, Explore Point of Interest (POI) CSV\n",
    "\n",
    "#Identify path to POI CSV\n",
    "path_poi = os.path.join(pitching_data_path, 'poi')\n",
    "\n",
    "#access poi data\n",
    "with open(os.path.join(path_poi, 'poi_metrics.csv'), 'r') as f:\n",
    "    poi = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show poi headers\n",
    "poi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print poi columns:\n",
    "print(poi.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting an error here, I think it's because I'm taking the mean of non ints/floats? But I copied his code exactly...\n",
    "#https://www.reddit.com/r/learnpython/comments/16r1ded/groupby_not_working/ (potential fix)\n",
    "#group poi data by session\n",
    "\n",
    "#poi_grouped = poi.groupby('session').mean()\n",
    "\n",
    "poi_grouped = poi.groupby('session')\n",
    "\n",
    "\n",
    "poi_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a scatterplot of max IR and pitch speed\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10,7), facecolor = 'white')\n",
    "plt.scatter(poi_grouped['max_shoulder_internal_rotational_velo'].mean(), poi_grouped['pitch_speed_mph'].mean(), s=50,c='#ffa300', alpha = 0.75, edgecolors = 'k')\n",
    "plt.xlabel(\"Shoulder Internal Rotation Velocity (degrees/second)\")\n",
    "plt.ylabel(\"Pitch Speed (mph)\")\n",
    "plt.title(\"Pitch Speed vs. Max Shoulder IR Velocity\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternative data visualization with correlation matrix from poi data\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "#select columns of interest\n",
    "columns_of_interest = ['pitch_speed_mph', 'max_shoulder_internal_rotational_velo', 'max_elbow_extension_velo', 'rear_grf_mag_max']\n",
    "\n",
    "#create a subset dataframe of the original dataframe with only the important columns\n",
    "subset_data = poi_grouped[columns_of_interest].mean()\n",
    "\n",
    "#calculate the correlation matrix\n",
    "correlation_matrix = subset_data.corr()\n",
    "\n",
    "#visualize the correlation matrix\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap= 'coolwarm', fmt='.2f')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a basic regression model\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#select the columns for the regression model\n",
    "columns_of_interest = ['pitch_speed_mph', 'max_torso_rotational_velo', 'rear_grf_mag_max', 'lead_grf_mag_max']\n",
    "\n",
    "#drop any rows with missing values\n",
    "data = poi_grouped[columns_of_interest].mean()\n",
    "data = data.dropna()\n",
    "\n",
    "#split the data into predictor variables (x) and the target variable (y)\n",
    "x = data[[\n",
    "    #'max_torso_rotational_velo',\n",
    "    #'rear_grf_mag_max',\n",
    "    #'lead_grf_mag_max'\n",
    "    'max_torso_rotational_velo'\n",
    "    ]]\n",
    "y = data['pitch_speed_mph']\n",
    "\n",
    "#add a constant column to the predictor variables (x) for the intercept term\n",
    "x = sm.add_constant(x)\n",
    "\n",
    "#fit the linear regression model\n",
    "model = sm.OLS(y, x).fit()\n",
    "\n",
    "#print the summary of the model\n",
    "print(model.summary())\n",
    "\n",
    "#visualize the residuals\n",
    "fig = plt.figure()\n",
    "residuals = model.resid\n",
    "sns.scatterplot(y=model.predict(x), x = model.fittedvalues)\n",
    "\n",
    "#End of Step 3 of tutorial, Explore Point of Interest (POI) CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start of Step 4 of tutorial, Explore Full Signal Timeseries Data\n",
    "\n",
    "# initialize python packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tkinter import filedialog\n",
    "from scipy import integrate\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simply identify file paths where data is stored\n",
    "\n",
    "#problem here is that it's a zip file not a csv, not sure how to unzip...\n",
    "#fixed: right click on the zip file in VSCode and click show in finder. Then double click the file in the finder and it will unzip itself and automatically show up as a CSV\n",
    "#then to get the file path right click on the CSV in VSCode and click copy path\n",
    "#r goes in front of the path to flip the back slash to forward slash?\n",
    "force_file = r'/Users/leofeingold/Documents/GitHub/openbiomechanics/baseball_pitching/data/full_sig/force_plate.csv'\n",
    "joint_angles_file = r'/Users/leofeingold/Documents/GitHub/openbiomechanics/baseball_pitching/data/full_sig/joint_angles.csv'\n",
    "\n",
    "#choose a file from your file explorer\n",
    "#not working\n",
    "#root = tk.Tk()\n",
    "#filename = tk.filedialog.askopenfilename()\n",
    "#root.destroy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file into a python pandas dataframe object\n",
    "master_force_data = pd.read_csv(force_file)\n",
    "\n",
    "#master_force_data.head(10)\n",
    "\n",
    "#identify force plate data for one particular trial within the dataframe\n",
    "#Essentially now able to analyze force data from just the single session labled '1031_2'\n",
    "trial_force_data = master_force_data.query(\"session_pitch == '1031_2'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot timeseries\n",
    "plt.plot(trial_force_data['time'], trial_force_data['rear_force_z'])\n",
    "plt.ylabel('Force (N)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.title(\"Rear Leg Vertical Force Over Time\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(trial_force_data['time'], trial_force_data['lead_force_z'])\n",
    "plt.ylabel('Force (N)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.title(\"Front Leg Vertical Force Over Time\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#timeseries indexing\n",
    "#max push-off force\n",
    "max_rear_force_z = max(trial_force_data['rear_force_z'])\n",
    "print(\"Max Rear Leg Vertical Force:\" , max_rear_force_z)\n",
    "\n",
    "frame_max_rear_force_z = np.where(trial_force_data['rear_force_z'] == max_rear_force_z)[0][0]\n",
    "print(\"Max rear leg vertical force occurs at frame:\" , frame_max_rear_force_z)\n",
    "\n",
    "time_max_rear_force_z = trial_force_data['time'][frame_max_rear_force_z]\n",
    "print(\"Max rear leg vertical force occures at time:\" , time_max_rear_force_z)\n",
    "\n",
    "#max touch down force\n",
    "max_lead_force_z = max(trial_force_data['lead_force_z'])\n",
    "print(\"Max Lead Leg Vertical Force:\" , max_lead_force_z)\n",
    "\n",
    "frame_max_lead_force_z = np.where(trial_force_data['lead_force_z'] == max_lead_force_z)[0][0]\n",
    "print(\"Max lead leg vertical force occurs at frame:\", frame_max_lead_force_z)\n",
    "\n",
    "time_max_lead_force_z = trial_force_data['time'][frame_max_lead_force_z]\n",
    "print(\"Max lead leg vertical force occurs at time:\", time_max_lead_force_z)\n",
    "\n",
    "#frame of intiial lead foot contact\n",
    "frame_initial_lead_foot_contact = np.where(trial_force_data['lead_force_z'][0:frame_max_lead_force_z] > 20)[0][0]\n",
    "print(\"Frame of foot plant:\" , frame_initial_lead_foot_contact)\n",
    "\n",
    "time_intiial_lead_foot_contact = trial_force_data['time'][frame_initial_lead_foot_contact]\n",
    "print(\"Time at foot plant:\" , time_intiial_lead_foot_contact)\n",
    "\n",
    "#filtering data (4th order lowpass butterworth)\n",
    "total_frames = len(trial_force_data['time'])\n",
    "total_time = trial_force_data['time'][total_frames - 1]\n",
    "fs = int(total_frames/total_time)\n",
    "cutoff = 50\n",
    "nyq = 0.5 * fs\n",
    "N = 4\n",
    "fc = cutoff/nyq\n",
    "b, a, = signal.butter(N, fc)\n",
    "\n",
    "#apply the filter\n",
    "lead_force = signal.filtfilt(b, a, trial_force_data['lead_force_z']) #this is the object holding the filtered data\n",
    "\n",
    "#derivation and integration\n",
    "#lead_impulse = integrate.cumtrapz(lead_force, trial_force_data['time']) #itegrate the filtered data with respet to time, use the line below because of function deprecation \n",
    "lead_impulse = integrate.cumulative_trapezoid(lead_force, trial_force_data['time'])\n",
    "\n",
    "lead_rfd = np.gradient(lead_force, trial_force_data['time'])\n",
    "max_lead_rfd = max(lead_rfd)\n",
    "\n",
    "print(\"Max Lead Leg Rate of Force Development:\" , max_lead_rfd)\n",
    "\n",
    "#store single timeseries to csv\n",
    "save_csv = pd.DataFrame({'Time': list(trial_force_data['time']), 'Force': list(trial_force_data['lead_force_z'])})\n",
    "pd.DataFrame.to_csv(save_csv, \"ENTER THE PATH TO THE LOCATION YOU WANT THE CSV HERE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
